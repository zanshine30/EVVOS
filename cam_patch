#!/bin/bash
# install_picam_upload.sh
#
# Self-contained installer for the EVVOS Pi Camera offline upload queue.
# Run directly on the Pi with:
#
#   curl -fsSL https://raw.githubusercontent.com/YOUR_USERNAME/YOUR_REPO/main/install_picam_upload.sh | sudo bash
#
# What this does:
#   1. Writes the Python patch to /tmp/patch_picam_offline_queue.py
#   2. Runs it with python3 (which patches evvos-picam-tcp.py and restarts the service)
#   3. Cleans up the temp file

set -e

RED='\033[0;31m'
GREEN='\033[0;32m'
CYAN='\033[0;36m'
NC='\033[0m'

echo ""
echo -e "${CYAN}══════════════════════════════════════════════════${NC}"
echo -e "${CYAN}  EVVOS Pi Camera — Offline Upload Queue Installer ${NC}"
echo -e "${CYAN}══════════════════════════════════════════════════${NC}"
echo ""

if [ "$EUID" -ne 0 ]; then
    echo -e "${RED}ERROR: Run as root: curl ... | sudo bash${NC}"
    exit 1
fi

PATCH_FILE="/tmp/patch_picam_offline_queue.py"

echo "Writing patch script to $PATCH_FILE ..."

cat > "$PATCH_FILE" << 'PYTHON_PATCH_EOF'
#!/usr/bin/env python3
"""
patch_picam_offline_queue.py  (v2 — video_filename fix)
Adds offline upload queue + background retry thread to evvos-picam-tcp.py
"""

import os, sys, subprocess, shutil
from datetime import datetime

SCRIPT_PATH = "/usr/local/bin/evvos-picam-tcp.py"

if os.geteuid() != 0:
    sys.exit("ERROR: Run as root")

if not os.path.exists(SCRIPT_PATH):
    sys.exit(f"ERROR: {SCRIPT_PATH} not found — run setup_picam.sh first.")

backup = f"{SCRIPT_PATH}.bak.{datetime.now().strftime('%Y%m%d_%H%M%S')}"
shutil.copy2(SCRIPT_PATH, backup)
print(f"✓ Backup: {backup}")

with open(SCRIPT_PATH) as fh:
    source = fh.read()

BLOCK_A = r'''
# ============================================================================
# OFFLINE UPLOAD QUEUE  (added by patch_picam_offline_queue.py v2)
# ============================================================================

import json as _json
import urllib.request as _urllib_req

QUEUE_PATH   = "/etc/evvos/upload_queue.json"
_queue_lock  = threading.Lock()


def _load_queue():
    try:
        with open(QUEUE_PATH) as fh:
            data = _json.load(fh)
            return data if isinstance(data, list) else []
    except FileNotFoundError:
        return []
    except Exception as exc:
        print(f"[QUEUE] Warning: could not read queue: {exc}", file=sys.stderr)
        return []


def _save_queue(queue):
    try:
        os.makedirs(os.path.dirname(QUEUE_PATH), exist_ok=True)
        with open(QUEUE_PATH, "w") as fh:
            _json.dump(queue, fh, indent=2)
    except Exception as exc:
        print(f"[QUEUE] Warning: could not save queue: {exc}", file=sys.stderr)


def _enqueue(job: dict):
    with _queue_lock:
        q = _load_queue()
        q = [x for x in q if x.get("incident_id") != job["incident_id"]]
        q.append(job)
        _save_queue(q)
    print(f"[QUEUE] Queued incident {job['incident_id']} (depth: {len(q)})")


def _dequeue(incident_id: str):
    with _queue_lock:
        q = [x for x in _load_queue() if x.get("incident_id") != incident_id]
        _save_queue(q)


def _has_internet(timeout=5):
    try:
        _urllib_req.urlopen("https://www.google.com", timeout=timeout)
        return True
    except Exception:
        return False


def _find_video_file(video_filename=None, session_id=None):
    """
    Locate the video file using multiple strategies, most specific first.
    Searches .mp4 and .h264 (covers ffmpeg failure fallback).
    """
    candidates = []

    if video_filename:
        candidates.append(RECORDINGS_DIR / video_filename)

    if session_id:
        ts = session_id.replace("session_", "")
        candidates.append(RECORDINGS_DIR / f"video_{ts}.mp4")
        candidates.append(RECORDINGS_DIR / f"video_{ts}.h264")

    for c in candidates:
        if c.exists() and c.stat().st_size > 0:
            print(f"[UPLOAD] Found video file: {c}")
            return str(c)

    all_videos = []
    for pattern in ("*.mp4", "*.h264"):
        all_videos.extend(RECORDINGS_DIR.glob(pattern))

    if all_videos:
        latest = max(all_videos, key=lambda f: f.stat().st_mtime)
        print(f"[UPLOAD] Using most recent video file: {latest}")
        return str(latest)

    return None


def _supabase_upload(file_path, incident_id, auth_token=None):
    import requests as _req

    url  = os.environ.get("SUPABASE_URL", "").rstrip("/")
    anon = os.environ.get("SUPABASE_ANON_KEY", "")
    if not url or not anon:
        raise RuntimeError("SUPABASE_URL / SUPABASE_ANON_KEY not set in /etc/evvos/config.env")

    storage_path = f"{incident_id}/video.mp4"
    upload_url   = f"{url}/storage/v1/object/incident-videos/{storage_path}"
    bearer       = auth_token if auth_token else anon

    size_mb = os.path.getsize(file_path) / 1024 / 1024
    print(f"[UPLOAD] Uploading {file_path} ({size_mb:.2f} MB) → {storage_path}")

    with open(file_path, "rb") as fh:
        resp = _req.post(
            upload_url,
            headers={
                "apikey":        anon,
                "Authorization": f"Bearer {bearer}",
                "Content-Type":  "video/mp4",
                "x-upsert":      "true",
            },
            data=fh,
            timeout=300,
        )

    if resp.status_code not in (200, 201):
        raise RuntimeError(f"Storage returned HTTP {resp.status_code}: {resp.text[:300]}")

    public_url = f"{url}/storage/v1/object/public/incident-videos/{storage_path}"
    print(f"[UPLOAD] ✓ Uploaded: {public_url}")
    return public_url, storage_path


def _notify_edge_function(incident_id, video_url, storage_path, auth_token=None):
    import requests as _req

    url  = os.environ.get("SUPABASE_URL", "").rstrip("/")
    anon = os.environ.get("SUPABASE_ANON_KEY", "")
    if not url or not anon:
        print("[NOTIFY] Skipping — credentials not set", file=sys.stderr)
        return

    bearer = auth_token if auth_token else anon
    try:
        resp = _req.post(
            f"{url}/functions/v1/notify-video-uploaded",
            headers={
                "apikey":        anon,
                "Authorization": f"Bearer {bearer}",
                "Content-Type":  "application/json",
            },
            json={"incident_id": incident_id, "video_url": video_url, "storage_path": storage_path},
            timeout=30,
        )
        if resp.status_code in (200, 201):
            print(f"[NOTIFY] ✓ Edge function updated incident {incident_id}")
        else:
            print(f"[NOTIFY] ⚠ HTTP {resp.status_code}: {resp.text[:200]}", file=sys.stderr)
    except Exception as exc:
        print(f"[NOTIFY] ⚠ Failed: {exc}", file=sys.stderr)


def _do_upload(incident_id, session_id=None, auth_token=None,
               video_filename=None, mp4_path_override=None):
    try:
        if mp4_path_override and os.path.exists(mp4_path_override):
            file_path = mp4_path_override
            print(f"[UPLOAD] Using queued path: {file_path}")
        else:
            file_path = _find_video_file(
                video_filename=video_filename,
                session_id=session_id,
            )

        if not file_path:
            return {
                "status":  "error",
                "message": (
                    f"No video file found in {RECORDINGS_DIR}. "
                    f"video_filename={video_filename!r}, session_id={session_id!r}. "
                    f"Check that ffmpeg completed successfully on the Pi."
                ),
            }

        file_size_mb = round(os.path.getsize(file_path) / 1024 / 1024, 2)
        video_url, storage_path = _supabase_upload(file_path, incident_id, auth_token)
        _notify_edge_function(incident_id, video_url, storage_path, auth_token)

        try:
            os.remove(file_path)
            print(f"[UPLOAD] ✓ Removed local file: {file_path}")
        except Exception as e:
            print(f"[UPLOAD] Warning: could not remove local file: {e}", file=sys.stderr)

        return {
            "status":       "upload_complete",
            "video_url":    video_url,
            "storage_path": storage_path,
            "incident_id":  incident_id,
            "session_id":   session_id,
            "file_size_mb": file_size_mb,
        }

    except Exception as exc:
        return {"status": "error", "message": str(exc)}


def upload_to_supabase_handler(incident_id, session_id=None, auth_token=None,
                                video_filename=None):
    if not incident_id:
        return {"status": "error", "message": "incident_id is required"}

    if not _has_internet():
        file_path = _find_video_file(video_filename=video_filename, session_id=session_id)
        job = {
            "incident_id":    incident_id,
            "session_id":     session_id,
            "video_filename": video_filename,
            "mp4_path":       file_path,
            "queued_at":      datetime.now().isoformat(),
        }
        _enqueue(job)
        return {
            "status":      "upload_queued",
            "incident_id": incident_id,
            "message":     "No internet — video queued for upload when connectivity returns.",
        }

    return _do_upload(incident_id, session_id, auth_token, video_filename)


def _retry_queue_loop(interval_seconds=60):
    print(f"[QUEUE] Retry thread started (interval: {interval_seconds}s)")
    while True:
        time.sleep(interval_seconds)
        with _queue_lock:
            queue = _load_queue()

        if not queue:
            continue

        print(f"[QUEUE] {len(queue)} job(s) pending — checking connectivity...")
        if not _has_internet():
            print("[QUEUE] No internet — will retry later")
            continue

        print(f"[QUEUE] Internet available — processing {len(queue)} job(s)")
        for job in list(queue):
            incident_id = job.get("incident_id")
            print(f"[QUEUE] Processing incident {incident_id}")
            result = _do_upload(
                incident_id=incident_id,
                session_id=job.get("session_id"),
                video_filename=job.get("video_filename"),
                mp4_path_override=job.get("mp4_path"),
            )
            if result["status"] == "upload_complete":
                _dequeue(incident_id)
                print(f"[QUEUE] ✓ Done: incident {incident_id}")
            else:
                print(f"[QUEUE] ✗ Still failing ({incident_id}): {result.get('message')}",
                      file=sys.stderr)

'''

BLOCK_B = '''
                    elif intent == "UPLOAD_TO_SUPABASE":
                        result = upload_to_supabase_handler(
                            incident_id=payload.get("incident_id"),
                            session_id=payload.get("session_id"),
                            auth_token=payload.get("auth_token"),
                            video_filename=payload.get("video_filename"),
                        )
                        conn.sendall((json.dumps(result) + "\\n").encode("utf-8"))

'''

BLOCK_C = '''
    # Start offline-upload retry thread
    retry_thread = threading.Thread(target=_retry_queue_loop, daemon=True)
    retry_thread.start()

'''

TCP_SECTION = "# ============================================================================\n# TCP SERVER"
ELSE_MARKER = "                    else:\n                        print(f\"[TCP] Unknown command: {intent}\")"
HTTP_THREAD = "    http_thread = threading.Thread(target=start_http_server, daemon=True)\n    http_thread.start()"

errors = []

# Remove old BLOCK A if re-running
if "# OFFLINE UPLOAD QUEUE" in source:
    old_start = source.find("# ============================================================================\n# OFFLINE UPLOAD QUEUE")
    old_end   = source.find(TCP_SECTION, old_start)
    if old_start != -1 and old_end != -1:
        source = source[:old_start] + source[old_end:]
        print("↻ Removed previous BLOCK A (re-injecting updated version)")

# Block A
if TCP_SECTION not in source:
    errors.append("Cannot find '# TCP SERVER' marker for Block A")
else:
    source = source.replace(TCP_SECTION, BLOCK_A + TCP_SECTION, 1)
    print("✓ Block A injected (upload handler + queue + retry thread)")

# Block B
if '"UPLOAD_TO_SUPABASE"' in source:
    print("⚠ Block B already present — skipping")
elif ELSE_MARKER not in source:
    errors.append("Cannot find 'else: Unknown command' marker for Block B")
else:
    source = source.replace(ELSE_MARKER, BLOCK_B + ELSE_MARKER, 1)
    print("✓ Block B injected (UPLOAD_TO_SUPABASE command branch)")

# Block C
if "retry_thread = threading.Thread(target=_retry_queue_loop" in source:
    print("⚠ Block C already present — skipping")
elif HTTP_THREAD not in source:
    errors.append("Cannot find http_thread block for Block C")
else:
    source = source.replace(HTTP_THREAD, HTTP_THREAD + "\n" + BLOCK_C, 1)
    print("✓ Block C injected (retry thread start in __main__)")

if errors:
    print("\nERRORS — patch NOT written:")
    for e in errors:
        print(f"  • {e}")
    import sys; sys.exit(1)

with open(SCRIPT_PATH, "w") as fh:
    fh.write(source)
print(f"✓ Patched script saved to {SCRIPT_PATH}")

import subprocess
r = subprocess.run(["systemctl", "restart", "evvos-picam-tcp.service"],
                   capture_output=True, text=True)
if r.returncode != 0:
    import sys; sys.exit(f"ERROR restarting service:\n{r.stderr}")

print("✓ Service restarted")
print("")
print("Verify:  sudo journalctl -u evvos-picam-tcp -f")
print("Files:   ls -lh ~/recordings/")
print("Queue:   cat /etc/evvos/upload_queue.json")
print("Done!")
PYTHON_PATCH_EOF

echo -e "${GREEN}✓ Patch script written to $PATCH_FILE${NC}"
echo ""
echo "Running patch..."
echo ""

python3 "$PATCH_FILE"
EXIT_CODE=$?

rm -f "$PATCH_FILE"

if [ $EXIT_CODE -eq 0 ]; then
    echo ""
    echo -e "${GREEN}══════════════════════════════════════════════════${NC}"
    echo -e "${GREEN}✓ Install complete!${NC}"
    echo -e "${GREEN}══════════════════════════════════════════════════${NC}"
else
    echo ""
    echo -e "${RED}✗ Patch failed (exit code $EXIT_CODE)${NC}"
    exit $EXIT_CODE
fi
